{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def find_files(folder_path, expression):\n",
    "    \"\"\"\n",
    "    Finds all files in the specified folder that match the given expression.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder to search.\n",
    "        expression (str): A glob expression to match file names.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    files = glob.glob(os.path.join(folder_path, expression))\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pysam\n",
    "\n",
    "def process_bed_bam_pairs(bed_files, bam_files):\n",
    "    \"\"\"\n",
    "    Processes pairs of BED and BAM files, calculating feature counts for each pair and writing the results to JSON files.\n",
    "\n",
    "    Args:\n",
    "        bed_files (list[str]): A list of BED file paths.\n",
    "        bam_files (list[str]): A list of BAM file paths.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    for bed_file, bam_file in zip(bed_files, bam_files):\n",
    "        # Process the bed and bam file pair and get the feature counts\n",
    "        feature_counts = process_bed_bam_pair(bed_file, bam_file)\n",
    "\n",
    "        # Create the JSON filename by combining the bed and bam filenames\n",
    "        json_filename = f\"{os.path.basename(bed_file)}_{os.path.basename(bam_file)}.json\"\n",
    "\n",
    "        # Prepare JSON data for the current bed-bam pair\n",
    "        json_data = {\n",
    "            \"bed_file\": bed_file,\n",
    "            \"bam_file\": bam_file,\n",
    "            \"feature_counts\": feature_counts\n",
    "        }\n",
    "\n",
    "        # Write the combined JSON data to a single JSON file\n",
    "        with open(json_filename, \"w\") as json_file:\n",
    "            json.dump(json_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bed_bam_pair(bed_file, bam_file):\n",
    "    \"\"\"\n",
    "    Calculates feature counts for a given pair of BED and BAM files.\n",
    "\n",
    "    Args:\n",
    "        bed_file (str): The path to the BED file containing genomic features.\n",
    "        bam_file (str): The path to the BAM file containing aligned reads.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, int]: A dictionary mapping feature keys to their respective counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the bed file and bam file\n",
    "    with gzip.open(bed_file, 'rt') as bed_handle, pysam.Samfile(bam_file, 'rb') as bam_handle:\n",
    "        # Create a dictionary to store feature counts\n",
    "        feature_counts = {}\n",
    "\n",
    "        # Iterate over the features in the bed file\n",
    "        for line in bed_handle:\n",
    "            # Extract the feature information from the bed line\n",
    "            chrom, start, end = line.strip().split('\\t')\n",
    "\n",
    "            # Create a key for the feature\n",
    "            feature_key = f\"{chrom}:{start}-{end}\"\n",
    "\n",
    "            # Initialize the count for the feature\n",
    "            feature_counts.setdefault(feature_key, 0)\n",
    "\n",
    "            # Iterate over the reads in the bam file that overlap the feature\n",
    "            for read in bam_handle.fetch(chrom, int(start), int(end)):\n",
    "                # Increment the count for the feature\n",
    "                feature_counts[feature_key] += 1\n",
    "\n",
    "    return feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main script\n",
    "#Step 1 get files in folder with certain expressions\n",
    "bam_files = find_files(\"../data/input/\",\"*.bam\")\n",
    "bed_files = find_files(\"../data/input/\",\"*.bed*\")\n",
    "sorted_bam_files = []\n",
    "\n",
    "#Step 2: Go over bam files sorting and indexing. \n",
    "for file in bam_files:\n",
    "    output_folder = \"../data/processed/\"\n",
    "    pysam.sort(\"-o\",os.path.join(output_folder,f\"sorted_{os.path.basename(file)}\"),file)\n",
    "    sorted_bam_files.append(os.path.join(output_folder,f\"sorted_{os.path.basename(file)}\"))\n",
    "    pysam.index(\"-o\",os.path.join(output_folder,f\"sorted_{os.path.basename(file)}.bai\"), os.path.join(output_folder,f\"sorted_{os.path.basename(file)}\"))\n",
    "\n",
    "# Process all bed-bam file pairs\n",
    "process_bed_bam_pairs(bed_files, sorted_bam_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextflow_docker_pipeline-Hl3wMurN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
